<script>document.title = "Field Matters";</script>

<head>
<meta property="og:title" content="Field Matters">
<meta property="og:description" content="The Third Workshop on NLP Applications to Field Linguistics">
<meta property="og:image" content="https://github.com/field-matters/field-matters.github.io/blob/main/logo.jpg?raw=true">
</head>

# Field Matters 2025
## Workshop description

Field linguistics plays a crucial role in the development of linguistic theory and universal language modelling, as it provides uncontested, the only way to obtain structural data about the rapidly diminishing diversity of natural languages.

The Field matters workshop aims to bring together the urgent needs of field linguists and the vast community of NLP practitioners, developing up-to-date NLP tools for easier, faster, more reliable data collection and annotation.

## Important links

**The workshop will take place at [ACL 2025](https://2025.aclweb.org/) on August 1, 2025**  
**The ACL 2025 will be held in Vienna from July, 27, to August, 1**

+ [Follow us on Twitter](https://twitter.com/field_matters)
+ Contact email: [`fieldmattersworkshop@gmail.com`](mailto:fieldmattersworkshop@gmail.com)
+ [Call for Papers](https://field-matters.github.io/cfp2025)
+ [Workshop program](https://field-matters.github.io/program2025)

## <a name="speakers"/>Invited talks

### Alexis Michaud  
**Title**: *Archives, Algorithms, and Alliances: Grounding NLP in the Realities of Language Documentation*

This talk offers a linguist’s perspective on the evolving place of NLP in language documentation, focusing on the interplay between archives (as both legacy and infrastructure), algorithms (with ASR on the Na language as an example), and alliances (the human networks that sustain such work). Drawing on experience within “Computational Language Documentation” projects led by computer scientists, I reflect on shared goals, realistic expectations, and the practical conditions required to keep interdisciplinary teams motivated over time.

---

### Eduardo Sanchez  
**Title**: *A Few Good Texts: How Small Sets of High-Quality Linguistic Data Power Massive Multilinguality in Language Models*

While scale remains a key driver of performance in multilingual language models, it’s not always an option, especially for low-resource languages where data is scarce or noisy. We'll explore how small, high-quality datasets can play a surprisingly powerful role in enabling multilinguality, especially where coverage gaps exist. Beyond parallel corpora, we'll show how strategic use of linguistic resources can complement large-scale training, improve generalization, and unlock better performance for underserved languages. A few good texts, chosen well, may be worth billions of tokens, and for many languages, they may be the key to ensuring visibility, usability, and survival in the digital age.

---

### Robert Forkel  
**Title**: *Connecting the Dots – Growing an Eco-system for Cross-linguistic Data*

One of the key contributions typology can make to multilingual NLP is a fuller picture of the diversity of the world's languages. This diversity is also reflected in widely varying documentation across languages. Thus, informing computational approaches to language processing by this diversity requires operationalizing a variety of data types describing very different languages. Getting a computational grasp on cross-linguistic information has been the main motivation behind CLDF – the Cross-Linguistic Data Formats. This talk will explore the eco-system of cross-linguistic data that is now opened up via CLDF.

---

### Lisa Bylinina  
**Title**: *(L)LMs and Language Theory*

One of the central questions in linguistic typology is: What constrains the space of natural languages? In a somewhat narrower formulation: How do different grammatical properties of a language relate to each other, and why are some combinations of features that would, in principle, be possible, in fact not attested? I would like to put these questions in the context of recent language models. Can (L)LMs help us understand interconnections within linguistic grammatical systems? I will argue for a moderately optimistic view and suggest some ways to make progress in this direction, with a focus on the linguistic generalisations (L)LMs make under different training conditions. My goal is to encourage discussion about the usefulness of (L)LMs for theoretical and typological linguistic research.

## Program Committee
+ Alexandre Arkhipov (University of Hamburg)
+ Emily Prud’hommeaux (Boston College)
+ Zoey Liu (Boston College)
+ Harald Hammarström (Max Planck Institute
for the Science of Human History)
+ He Zhou (Hong Kong Polytechnic University)
+ Ezequiel Koile (Max Planck In-
stitute for the Science of Human History)
+ Bonaveture Dossou (Jacobs University Bremen,
Germany)
+ Vitaly Protasov (Independent Researcher)
+ Vladislav Mikhailov (University of Oslo)
+ Katharina Kann (University of Colorado Boulder)
+ Tatiana Shavrina (Meta)
+ Tessa Masis (University of Massachusetts
Amherst)
+ Nadezhda Zueva (intone.io)
+ Kilian Evang (Heinrich Heine University Düs-
seldorf)
+ Albert Ventayol-Boada (University of Califor-
nia, Santa Barbara)

## Organizers

**Oleg Serikov**
(KAUST, HSE University, 
[`oleg.serikov@kaust.edu.sa`](mailto:oleg.serikov@kaust.edu.sa))

is an NLP Researcher. 
Oleg now writes his PhD thesis at HSE University, his main points of interest are under-resourced languages ASR, under-resourced languages modelling and linguistic interpretation of language models. He is also an ML Engineer @ KAUST AI Initiative.
He co-organized SIGTYP 2021 and LowResourceEval 2021 shared tasks on under-resourced languages ASR.

**Elena Klyachko**
(HSE University,
[`elenaklyachko@gmail.com`](mailto:elenaklyachko@gmail.com))

is a PhD student at HSE. Her main points of interest are Tungusic languages, which she has been studying during her fieldwork, as well as low-resource NLP.
She co-organized the SIGMORPHON 2020-2021 shared tasks on morphological reinflection, 
LowResourceEval 2019, 2021 shared tasks on NLP for field linguistic data and
SigTyp 2021 shared task on under-resourced languages ASR.

**Francis Tyers**
(Indiana University,
[`ftyers@iu.edu`](mailto:ftyers@iu.edu))

has a huge experience with under-resourced languages processing. His reseach interests include modelling the grammar of polysyntetic languages, and application of finite-state methods to NLP. Francis is one of the core contributors of Apertium machine translation project. He has an experience of co-organizing workshops and shared tasks, including SIGMORPHON 2020-2021, CoNLL 2018.

**Ekaterina Vylomova**
(University of Melbourne,
[`evylomova@gmail.com`](mailto:evylomova@gmail.com)) 

is a Lecturer and a Postdoctoral Fellow at the University of Melbourne. Her research is focused on modelling of  morphology and computational approaches to linguistics typology. She is the president of SIGTYP, co-organized the SIGTYP 2019-2021 workshops and the SIGMORPHON 2017-2021 shared tasks on morphological reinflection. 

**Éric Le Ferrand**
(Boston College,
[`leferran@bc.edu`](mailto:leferran@bc.edu)) 

is a post-doctoral researcher. His main point of interest is speech recognition for under-resourced languages. His current research project is about the exploration of modern speech recognition methods applied to Creole languages. He built linguistic fieldwork expertise during his PhD, deploying speech recognition-based transcription tools in Australian Aboriginal Country.

**Ekaterina Voloshina** 
(University of Gothenburg, Chalmers University of Technology, 
[`ekaterina.voloshina@chalmers.se`](mailto:ekaterina.voloshina@chalmers.se))

is a PhD candidate in computer science at University of Gothenburg and Chalmers University of Technology. Her research interests are mainly computational and quantitive approaches to language description and 
modelling.

**Anna Postnikova** 
(Independent Researcher,
[`anna.postn90@gmail.com`](mailto:anna.postn90@gmail.com))

is an researcher focused on field linguistics, formal syntax, and under-resourced languages documentation, particularly Tungusic languages.

**Tatiana Shavrina**
(Meta, 
[`rybolos@gmail.com`](mailto:rybolos@gmail.com))

Is an expert in multidisciplinary applications of NLP and the methodology of science. Her research focus is on the evaluation of the language models following her PhD specifics.

## Paper submission 
We invite both archival and non-archival submissions. 
Non-archival submissions are 2-page abstracts that could present already published work or work in progress. 
Archival submissions should be either 4- or 8-pages long.

## Dual submissions and preprints
Dual submissions with the main conference are allowed, but authors must declare dual submission by entering the paper’s main conference submission id. 
The reviews for the submission for the main conference will be automatically forwarded to the workshop and taken into consideration when your paper is evaluated. Authors of dual-submission papers accepted to the main conference should retract them from the workshop by March 13.

Papers posted to preprint servers such as arxiv can be submitted without any restrictions on when they were posted.

## Camera-ready information
Authors of accepted archival papers should upload the final version of their paper to the submission system by the camera-ready deadline. Authors may use one extra page to address reviewer comments, for a total of nine pages.

## Anti-Harassment Policy
Field matters 2025 adheres to the [ACL Anti-Harassment Policy](https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy).

## Demographic Diversity
We encourage diversity in all forms. 
Workshop organizers make it their top priority the freedom of thought and expression, as well as respectful scientific debate. 
On behalf of the organizing team, we are committed to the principles of gender and sociodemographic diversity and are guided by these principles in the consideration of the workshop team, including the selection of invited speakers and PC.
